{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8kuYKBJaiezq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U8ljhRuTjwL_"
      },
      "outputs": [],
      "source": [
        "# URL del CSV con los enlaces de descarga\n",
        "csv_url = 'https://docs.google.com/spreadsheets/d/1azJrrovCMYBeRasAOwh-87nVSxQPdjRs2AfBoKy97-0/export?format=csv'\n",
        "output_directory = 'drive'\n",
        "temp_directory = 'temp_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SqJflTDTjwJB"
      },
      "outputs": [],
      "source": [
        "# Crear los directorios necesarios\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "os.makedirs(temp_directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DiTMn16_veFC"
      },
      "outputs": [],
      "source": [
        "# Configuración del navegador para la descarga automática\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "prefs = {\n",
        "    'download.default_directory': os.path.abspath(output_directory),\n",
        "    'download.prompt_for_download': False,\n",
        "    'download.directory_upgrade': True,\n",
        "    'safebrowsing.enabled': True\n",
        "}\n",
        "chrome_options.add_experimental_option('prefs', prefs)\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xqprgJcAjwDV"
      },
      "outputs": [],
      "source": [
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "wait = WebDriverWait(driver, 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4N8xagTljwAT"
      },
      "outputs": [],
      "source": [
        "# Descargar el archivo CSV con los enlaces de descarga\n",
        "response = requests.get(csv_url)\n",
        "url_drives = []\n",
        "if response.status_code == 200:\n",
        "    drives = response.content.decode('utf-8').split('\\n')\n",
        "    for i in range(1, len(drives)):\n",
        "        drives[i] = drives[i].replace('no con jpeg y txt', '')\n",
        "        drives[i] = drives[i].replace('\"', '')\n",
        "        columns = drives[i].split(',')\n",
        "        link = columns[-1].strip()\n",
        "        url_drives.append(link)\n",
        "else:\n",
        "    print(f\"Error al acceder a la hoja de cálculo: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxGNHmEGjv9S",
        "outputId": "ab7f8a27-d2ea-4613-d08d-ee9a5a0f9dd2"
      },
      "outputs": [],
      "source": [
        "# Descargar los archivos desde Google Drive\n",
        "for folder_url in url_drives:\n",
        "    driver.get(folder_url)\n",
        "    time.sleep(10)  # Aumentar el tiempo de espera para asegurar que la página se cargue completamente\n",
        "\n",
        "    try:\n",
        "        # Intenta encontrar el botón de descarga\n",
        "        download_button = wait.until(\n",
        "            EC.element_to_be_clickable((By.XPATH, '//*[contains(text(), \"Descargar\") or contains(text(), \"Download\")]'))\n",
        "        )\n",
        "        download_button.click()\n",
        "        time.sleep(20)  # Esperar a que la descarga comience\n",
        "        print(f\"Descarga iniciada desde la carpeta: {folder_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al intentar descargar archivos de la carpeta {folder_url}: {e}\")\n",
        "\n",
        "driver.quit()\n",
        "print(\"Descarga completada.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ruM1gsfCjv6S"
      },
      "outputs": [],
      "source": [
        "# Directorios finales para las imágenes y las etiquetas\n",
        "images_directory = 'dataset_tmp/images'\n",
        "labels_directory = 'dataset_tmp/labels'\n",
        "extensiones_imagenes = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
        "\n",
        "# Crear directorios de imágenes y etiquetas si no existen\n",
        "os.makedirs(images_directory, exist_ok=True)\n",
        "os.makedirs(labels_directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R26aQ_9Qj9yB"
      },
      "outputs": [],
      "source": [
        "# Función para normalizar nombres de archivo\n",
        "def normalize_filename(filename):\n",
        "    filename = filename.lower()\n",
        "    filename = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore').decode('ascii')\n",
        "    filename = filename.replace(' ', '-').replace('_', '')\n",
        "    return filename\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lGWiJUUdj9vN"
      },
      "outputs": [],
      "source": [
        "# Función para copiar pares de archivos a los directorios correspondientes\n",
        "def copiar_pares(pares, img_dest, lbl_dest):\n",
        "    for imagen_path, txt_path in pares:\n",
        "        imagen_name = normalize_filename(os.path.basename(imagen_path))\n",
        "        txt_name = normalize_filename(os.path.basename(txt_path))\n",
        "\n",
        "        shutil.copy(imagen_path, os.path.join(img_dest, imagen_name))\n",
        "        shutil.copy(txt_path, os.path.join(lbl_dest, txt_name))\n",
        "\n",
        "        os.remove(imagen_path)\n",
        "        os.remove(txt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2qDqynYSj9sQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipped 'imagenes-20240710T141637Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'dataset coputer vision-20240710T142236Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'truco_simon_revello-20240710T143831Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Images_with_labels-20240710T070751Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Imágenes Dataset Leandro Salvañá-20240710T142147Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'fotos_tp_cv-20240710T051846Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'data_truco-20240710T143141Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'TUIA-VC-W05576-20240710T143441Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Fotos cartas -20240710T143232Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Imágenes de cartas - TP Final Visión por Computadora-20240710T070526Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'YOLODataset-20240710T142356Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'CV - Truco-20240710T143041Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'DATASET-20240710T141245Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'eugenio_lopez_dataset_truco-20240710T142604Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'dataset_truco-20240710T143703Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Computer Vision-20240710T143316Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'computer_vision-20240710T142804Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'YOLODataset-20240710T070824Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'CVFOTOS-20240710T143335Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'CV-20240710T142433Z-001.zip' in 'temp_dataset'\n",
            "Unzipped '9 Abril Rodriguez Cartas-20240710T142706Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Imágenes YOLO-20240710T142739Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'cartas CV-20240710T143020Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'yolo_dataset-20240710T143646Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Images_with_labels-20240710T141929Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'CARTAS-20240710T143903Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'CV - TP1-20240710T142458Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'cartas-20240710T143425Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Cartas-20240710T143552Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Sofía Rondini-20240710T143846Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Cartas-20240710T142924Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'data_truco-20240710T142958Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Imágenes Dataset Leandro Salvañá-20240710T071445Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'CVproyecto_dataset_imagenes-20240710T141832Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Cartas-20240710T143611Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'cartas-20240710T052006Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Imagenes_farias-20240710T142723Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'YOLODataset-20240710T144422Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'cartas-20240710T143732Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'tp-final-cv-TOMASNAVARRO-20240710T070557Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'Muestras-Cartas-CV-Mateo-Rovere-20240710T143212Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'cartasYOLO-20240710T142414Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'YOLODataset-20240710T142206Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'ComputerVision-20240710T142941Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'YOLODataset-20240710T143752Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'YOLODataset-20240710T143250Z-001.zip' in 'temp_dataset'\n",
            "Unzipped 'CV2024-20240710T143456Z-001.zip' in 'temp_dataset'\n",
            "Imágenes y etiquetas movidas desde 'cartas'\n",
            "Imágenes y etiquetas movidas desde 'YOLODataset'\n",
            "Imágenes y etiquetas movidas desde 'Imágenes de cartas - TP Final Visión por Computadora'\n",
            "Imágenes y etiquetas movidas desde 'CV2024'\n",
            "Imágenes y etiquetas movidas desde 'TUIA-VC-W05576'\n",
            "Imágenes y etiquetas movidas desde 'data_truco'\n",
            "Imágenes y etiquetas movidas desde 'ComputerVision'\n",
            "Imágenes y etiquetas movidas desde 'Muestras-Cartas-CV-Mateo-Rovere'\n",
            "Imágenes y etiquetas movidas desde 'Imágenes Dataset Leandro Salvañá'\n",
            "Imágenes y etiquetas movidas desde 'CV - TP1'\n",
            "Imágenes y etiquetas movidas desde 'Imagenes_farias'\n",
            "Imágenes y etiquetas movidas desde 'fotos_tp_cv'\n",
            "Imágenes y etiquetas movidas desde 'Imágenes YOLO'\n",
            "Imagen '429816_cesar_donnarumma_07.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_12.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_31.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_22.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_06.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_04.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_23.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_10.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_21.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_14.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_30.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_15.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_27.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_17.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_02.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_19.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_20.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_08.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_16.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_13.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_29.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_24.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_18.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_05.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_25.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_09.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_01.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_28.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_11.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_03.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imagen '429816_cesar_donnarumma_26.png' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imágenes y etiquetas movidas desde 'Cartas'\n",
            "Imágenes y etiquetas movidas desde 'yolo_dataset'\n",
            "Imágenes y etiquetas movidas desde 'Fotos cartas '\n",
            "Imágenes y etiquetas movidas desde 'R-4582-9 Abril Rodriguez Cartas'\n",
            "Imágenes y etiquetas movidas desde 'cartas CV'\n",
            "Imágenes y etiquetas movidas desde 'CARTAS'\n",
            "Imágenes y etiquetas movidas desde 'dataset coputer vision'\n",
            "Imágenes y etiquetas movidas desde 'CVproyecto_dataset_imagenes'\n",
            "Imágenes y etiquetas movidas desde 'CV - Truco'\n",
            "Imágenes y etiquetas movidas desde 'Sofía Rondini'\n",
            "Imágenes y etiquetas movidas desde 'eugenio_lopez_dataset_truco'\n",
            "Imagen 'gravifiorino_2.jpeg' eliminada porque no tiene un archivo .txt correspondiente.\n",
            "Imágenes y etiquetas movidas desde 'CV'\n",
            "Imágenes y etiquetas movidas desde 'Images_with_labels'\n",
            "Imágenes y etiquetas movidas desde 'cartasYOLO'\n",
            "Imágenes y etiquetas movidas desde 'truco_simon_revello'\n",
            "Imágenes y etiquetas movidas desde 'dataset_truco'\n",
            "Imágenes y etiquetas movidas desde 'computer_vision'\n",
            "Imágenes y etiquetas movidas desde 'imagenes'\n",
            "Imágenes y etiquetas movidas desde 'tp-final-cv-TOMASNAVARRO'\n",
            "Imágenes y etiquetas movidas desde 'CVFOTOS'\n",
            "Imágenes y etiquetas movidas desde 'Computer Vision'\n",
            "Imágenes y etiquetas movidas desde 'DATASET'\n",
            "Carpeta 'drive' eliminada.\n"
          ]
        }
      ],
      "source": [
        "# Procesar los archivos descargados\n",
        "if os.path.exists(output_directory):\n",
        "    for file in os.listdir(output_directory):\n",
        "        if file.endswith('.zip'):\n",
        "            file_path = os.path.join(output_directory, file)\n",
        "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(temp_directory)\n",
        "                print(f\"Unzipped '{file}' in '{temp_directory}'\")\n",
        "\n",
        "    for item in os.listdir(temp_directory):\n",
        "        item_path = os.path.join(temp_directory, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            pares_imagen_txt = []\n",
        "\n",
        "            for archivo in os.listdir(item_path):\n",
        "                if os.path.splitext(archivo)[1].lower() in extensiones_imagenes:\n",
        "                    archivo_txt = os.path.splitext(archivo)[0] + '.txt'\n",
        "                    if archivo_txt in os.listdir(item_path):\n",
        "                        pares_imagen_txt.append(\n",
        "                            (os.path.join(item_path, archivo), os.path.join(item_path, archivo_txt)))\n",
        "                    else:\n",
        "                        os.remove(os.path.join(item_path, archivo))\n",
        "                        print(f\"Imagen '{archivo}' eliminada porque no tiene un archivo .txt correspondiente.\")\n",
        "\n",
        "            copiar_pares(pares_imagen_txt, images_directory, labels_directory)\n",
        "            print(f\"Imágenes y etiquetas movidas desde '{item}'\")\n",
        "\n",
        "    # Limpiar la carpeta de descarga\n",
        "    shutil.rmtree(output_directory)\n",
        "    print(f\"Carpeta '{output_directory}' eliminada.\")\n",
        "else:\n",
        "    print(f\"El directorio '{output_directory}' no existe.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uk8mHdvIj9pn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b1Wvw8xzj9nL"
      },
      "outputs": [],
      "source": [
        "# Directorios de entrada y salida\n",
        "temp_images_directory = 'dataset_tmp/images'\n",
        "temp_labels_directory = 'dataset_tmp/labels'\n",
        "final_images_directory = 'dataset_tmp/images'  # Directorio final para imágenes válidas\n",
        "final_labels_directory = 'dataset_tmp/labels'  # Directorio final para etiquetas válidas\n",
        "label_errors_directory = 'dataset/label_errors'\n",
        "os.makedirs(final_images_directory, exist_ok=True)\n",
        "os.makedirs(final_labels_directory, exist_ok=True)\n",
        "os.makedirs(label_errors_directory, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rlJIslcqj9kn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 646/1513 [00:54<01:22, 10.52it/s]Invalid SOS parameters for sequential JPEG\n",
            "100%|██████████| 1513/1513 [02:10<00:00, 11.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos procesados: 1434\n",
            "Archivos con errores: 79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Función para verificar y unificar anotaciones en formato YOLOv5\n",
        "def validar_y_unificar_anotaciones(images_dir, labels_dir, final_images_dir, final_labels_dir, label_errors_dir):\n",
        "    extensiones_imagenes = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
        "    archivos_procesados = 0\n",
        "    archivos_con_errores = 0\n",
        "\n",
        "    for label_file in tqdm(os.listdir(labels_dir)):\n",
        "        if label_file.endswith('.txt'):\n",
        "            label_path = os.path.join(labels_dir, label_file)\n",
        "            image_path = None\n",
        "\n",
        "            for ext in extensiones_imagenes:\n",
        "                potential_image_path = os.path.join(images_dir, os.path.splitext(label_file)[0] + ext)\n",
        "                if os.path.exists(potential_image_path):\n",
        "                    image_path = potential_image_path\n",
        "                    break\n",
        "\n",
        "            if image_path is None:\n",
        "                shutil.move(label_path, os.path.join(label_errors_dir, os.path.basename(label_path)))\n",
        "                archivos_con_errores += 1\n",
        "                continue\n",
        "\n",
        "            # Leer imagen\n",
        "            image = cv2.imread(image_path)\n",
        "            height, width, _ = image.shape\n",
        "\n",
        "            # Leer anotaciones\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            valid_lines = []\n",
        "            error_found = False\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    id_clase, x_centro, y_centro, ancho, alto = map(float, parts)\n",
        "                elif len(parts) == 9:\n",
        "                    id_clase, x_centro, y_centro, ancho, alto = map(float, parts[:5])\n",
        "                else:\n",
        "                    error_found = True\n",
        "\n",
        "                # Verificar límites y convertir a formato YOLOv5\n",
        "                if not (0 <= x_centro <= 1 and 0 <= y_centro <= 1 and 0 <= ancho <= 1 and 0 <= alto <= 1):\n",
        "                    error_found = True\n",
        "\n",
        "                # Verificar que la etiqueta esté en el rango 0-48\n",
        "                if not (0 <= id_clase <= 48):\n",
        "                    error_found = True\n",
        "\n",
        "                if error_found:\n",
        "                    break\n",
        "                else:\n",
        "                    valid_lines.append(f\"{int(id_clase)} {x_centro} {y_centro} {ancho} {alto}\\n\")\n",
        "\n",
        "            if error_found:\n",
        "                archivos_con_errores += 1\n",
        "                shutil.move(label_path, os.path.join(label_errors_dir, os.path.basename(label_path)))\n",
        "                os.remove(image_path)\n",
        "            else:\n",
        "                # Escribir anotaciones válidas y mover archivos\n",
        "                with open(os.path.join(final_labels_dir, os.path.basename(label_path)), 'w') as f:\n",
        "                    f.writelines(valid_lines)\n",
        "                archivos_procesados += 1\n",
        "\n",
        "    print(f\"Archivos procesados: {archivos_procesados}\")\n",
        "    print(f\"Archivos con errores: {archivos_con_errores}\")\n",
        "\n",
        "validar_y_unificar_anotaciones(temp_images_directory, temp_labels_directory, final_images_directory, final_labels_directory, label_errors_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validar_y_unificar_anotaciones(temp_images_directory, temp_labels_directory, final_images_directory, final_labels_directory, label_errors_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kq99uenuj9iH"
      },
      "outputs": [],
      "source": [
        "# División del dataset en entrenamiento, validación y prueba\n",
        "image_files = [f for f in os.listdir(final_images_directory) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
        "train_files, test_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
        "train_files, val_files = train_test_split(train_files, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qD8tNZDOj9fZ"
      },
      "outputs": [],
      "source": [
        "# Crear directorios para los splits\n",
        "split_dirs = {\n",
        "    'train': {'images': 'dataset/train/images', 'labels': 'dataset/train/labels'},\n",
        "    'val': {'images': 'dataset/val/images', 'labels': 'dataset/val/labels'},\n",
        "    'test': {'images': 'dataset/test/images', 'labels': 'dataset/test/labels'}\n",
        "}\n",
        "for split in split_dirs:\n",
        "    os.makedirs(split_dirs[split]['images'], exist_ok=True)\n",
        "    os.makedirs(split_dirs[split]['labels'], exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1ZpYHcTb0pOb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de imágenes en el conjunto de entrenamiento: 860\n",
            "Cantidad de imágenes en el conjunto de validación: 287\n",
            "Cantidad de imágenes en el conjunto de prueba: 287\n"
          ]
        }
      ],
      "source": [
        "# Función para mover archivos a sus directorios correspondientes\n",
        "def mover_archivos(files, split):\n",
        "    for file in files:\n",
        "        shutil.copy(os.path.join(final_images_directory, file), split_dirs[split]['images'])\n",
        "        shutil.copy(os.path.join(final_labels_directory, os.path.splitext(file)[0] + '.txt'), split_dirs[split]['labels'])\n",
        "\n",
        "mover_archivos(train_files, 'train')\n",
        "mover_archivos(val_files, 'val')\n",
        "mover_archivos(test_files, 'test')\n",
        "\n",
        "# Reporte de la cantidad de imágenes en cada split\n",
        "print(f\"Cantidad de imágenes en el conjunto de entrenamiento: {len(train_files)}\")\n",
        "print(f\"Cantidad de imágenes en el conjunto de validación: {len(val_files)}\")\n",
        "print(f\"Cantidad de imágenes en el conjunto de prueba: {len(test_files)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
